# Use Case: Automated Readiness Assessment Document Generation

## Overview
This n8n workflow automatically generates a readiness assessment document by analyzing demo call transcripts using AI. When triggered via webhook, it retrieves a project's demo transcript from Supabase, analyzes it with GPT-4o to evaluate customer readiness and automation feasibility, then saves the generated assessment back to Supabase storage.

## What the Workflow Should Do
Create an intelligent document generation pipeline that:
1. Receives a project identifier via webhook
2. Retrieves the associated demo call transcript from Supabase storage
3. Uses AI (GPT-4o) to analyze the transcript and generate a comprehensive readiness assessment
4. Saves the generated assessment as a text file to Supabase storage
5. Records the file metadata in the database for tracking and retrieval

## How It Starts (Trigger)
**Webhook Node** - Listens for POST requests
- **Method**: POST
- **Expected Payload**:
  ```json
  {
    "project_id": "<uuid>"
  }
  ```
- **Authentication**: Configure as needed (e.g., header token, basic auth)
- **Response Mode**: Should wait for workflow completion to return success/failure

## Step-by-Step Process

### Step 1: Receive Webhook Request
- Capture the incoming `project_id` from the webhook payload
- Validate that `project_id` is present and is a valid UUID format

### Step 2: Query Supabase for Demo Transcript File Metadata
- **Query**: `strms_project_files` table
- **Filter Criteria**:
  - `project_id` = webhook payload project_id
  - `file_type_id` = 'demo-transcript' (or similar identifier for demo transcripts)
- **Retrieved Fields**:
  - `file_name`
  - `file_path` or `storage_path`
  - `storage_bucket` (should be 'strms-project-files')
  - `id` (file record ID)

### Step 3: Download Transcript File from Supabase Storage
- **Storage Bucket**: `strms-project-files`
- **File Path**: Use the `storage_path` from Step 2
- **Output**: Raw transcript text content

### Step 4: AI Analysis with OpenAI GPT-4o
- **Model**: GPT-4o (or gpt-4-turbo if 4o not available)
- **System Prompt**:
  ```
  You are an expert business analyst specializing in automation readiness assessments.
  Analyze the provided demo call transcript and create a comprehensive readiness assessment document.
  ```
- **User Prompt**:
  ```
  Analyze this demo call transcript and create a readiness assessment with the following sections:

  1. CUSTOMER READINESS ASSESSMENT
     - Technical capability to implement proposed automations
     - Organizational readiness (leadership support, change management)
     - Resource availability (time, budget, personnel)
     - Overall readiness score (High/Medium/Low)

  2. AUTOMATION FEASIBILITY ANALYSIS
     - Technical complexity of proposed solutions
     - Integration requirements and challenges
     - Timeline expectations and realism
     - Resource requirements
     - Overall feasibility score (High/Medium/Low)

  3. RECOMMENDATION
     - Clear go/no-go recommendation
     - Key success factors if proceeding
     - Potential roadblocks to address
     - Suggested next steps

  Transcript:
  {{ $json.transcript_content }}
  ```
- **Temperature**: 0.3-0.5 (for consistent, analytical output)
- **Max Tokens**: 2000-3000 (sufficient for detailed assessment)

### Step 5: Format AI Output as Text Document
- **Content**: The AI-generated assessment
- **Formatting**:
  - Add header with metadata (project ID, generation date, timestamp)
  - Preserve section structure from AI response
  - Add footer with disclaimer/version info
- **Example Header**:
  ```
  ===================================================
  READINESS ASSESSMENT DOCUMENT
  ===================================================
  Project ID: {{ $json.project_id }}
  Generated: {{ $now.format('YYYY-MM-DD HH:mm:ss') }}
  Generated By: AI Automation (GPT-4o)
  ===================================================

  [AI content here]

  ===================================================
  End of Assessment
  Generated automatically by GrowthLab AI Console
  ===================================================
  ```

### Step 6: Generate Unique Filename
- **Naming Convention**: `project_${project_id}_readiness_assessment_${timestamp}.txt`
- **Example**: `project_a1b2c3d4-e5f6-7890-abcd-ef1234567890_readiness_assessment_20250114_143522.txt`
- **Timestamp Format**: YYYYMMDD_HHMMSS (for sortability)

### Step 7: Upload to Supabase Storage
- **Bucket**: `strms-project-files`
- **Storage Path**: `${project_id}/assessments/${filename}`
- **Content Type**: `text/plain`
- **File Content**: Formatted text document from Step 5

### Step 8: Insert File Metadata Record
- **Table**: `strms_project_files`
- **Fields to Insert**:
  - `id`: Generate new UUID
  - `project_id`: From webhook payload
  - `file_type_id`: 'readiness-assessment'
  - `file_name`: Generated filename from Step 6
  - `file_path`: Storage path used in upload
  - `file_size`: Size in bytes of uploaded file
  - `uploaded_by`: 'system' or 'n8n-workflow'
  - `uploaded_at`: Current timestamp (auto-generated)
  - `storage_bucket`: 'strms-project-files'
  - `storage_path`: Storage path from Step 7

### Step 9: Return Success Response
- **Status**: 200 OK
- **Response Body**:
  ```json
  {
    "success": true,
    "project_id": "{{ $json.project_id }}",
    "assessment_file_id": "{{ $json.file_record_id }}",
    "file_name": "{{ $json.file_name }}",
    "message": "Readiness assessment generated successfully"
  }
  ```

## Services Connected

### 1. Webhook (Trigger)
- **Purpose**: Receive workflow initiation requests
- **Authentication**: May require API key or token validation

### 2. Supabase PostgreSQL Database
- **Tables Used**:
  - `strms_project_files` - Query for transcript metadata, insert assessment metadata
  - `strms_projects` - (Optional) May query for additional project context
- **Operations**: SELECT, INSERT

### 3. Supabase Storage
- **Bucket**: `strms-project-files`
- **Operations**:
  - Download (read transcript file)
  - Upload (save assessment file)

### 4. OpenAI API
- **Model**: GPT-4o (or gpt-4-turbo)
- **Purpose**: Analyze transcript and generate readiness assessment
- **API Key**: Required in n8n credentials

## Expected Output

### Immediate Response
JSON response indicating workflow success/failure with file details

### Stored Artifacts
1. **Text File in Supabase Storage**:
   - Location: `strms-project-files/${project_id}/assessments/`
   - Format: Plain text (.txt)
   - Content: AI-generated readiness assessment with metadata headers
   - Size: ~5-15 KB (depending on assessment detail)

2. **Database Record in `strms_project_files`**:
   - Links generated assessment to project
   - Enables retrieval and tracking in application UI
   - Stores metadata (filename, size, upload time, etc.)

### Assessment Document Structure
```
Header (metadata)
├── Customer Readiness Assessment
│   ├── Technical Capability
│   ├── Organizational Readiness
│   ├── Resource Availability
│   └── Readiness Score
├── Automation Feasibility Analysis
│   ├── Technical Complexity
│   ├── Integration Requirements
│   ├── Timeline Assessment
│   └── Feasibility Score
└── Recommendation
    ├── Go/No-Go Decision
    ├── Success Factors
    ├── Potential Roadblocks
    └── Next Steps
Footer (disclaimer)
```

## What Could Go Wrong

### Trigger/Input Issues
1. **Missing project_id in webhook payload**
   - **Impact**: Workflow cannot proceed
   - **Handling**: Return 400 Bad Request with error message
   - **Prevention**: Validate webhook payload structure

2. **Invalid project_id format**
   - **Impact**: Database query fails
   - **Handling**: Validate UUID format, return 400 if invalid
   - **Prevention**: Add validation node after webhook

### Data Retrieval Issues
3. **No transcript found for project_id**
   - **Impact**: Cannot generate assessment without source data
   - **Handling**: Return 404 Not Found with message "No demo transcript found for project"
   - **Prevention**: Check if query returns results before proceeding

4. **Transcript file missing from storage**
   - **Impact**: Database has record but file doesn't exist in storage
   - **Handling**: Return 500 with message "Transcript file not accessible"
   - **Prevention**: Validate file exists before attempting download

5. **Empty or corrupted transcript file**
   - **Impact**: AI analysis receives invalid input
   - **Handling**: Return 422 Unprocessable Entity
   - **Prevention**: Check file size > 0 and content is readable text

### AI Processing Issues
6. **OpenAI API rate limit exceeded**
   - **Impact**: Temporary inability to process requests
   - **Handling**: Implement retry logic (3 attempts with exponential backoff)
   - **Prevention**: Monitor API usage, consider queueing system

7. **OpenAI API key invalid or expired**
   - **Impact**: All AI analysis fails
   - **Handling**: Return 500 with message "AI service unavailable"
   - **Prevention**: Store backup credentials, monitor API key validity

8. **Transcript too long for token limit**
   - **Impact**: OpenAI API rejects request
   - **Handling**: Truncate transcript intelligently or use chunking strategy
   - **Prevention**: Check token count before API call, implement summarization

9. **AI generates malformed or incomplete response**
   - **Impact**: Assessment document missing sections
   - **Handling**: Retry with adjusted prompt or return partial results with warning
   - **Prevention**: Use structured output format in prompt, validate response

### Storage/Database Issues
10. **Supabase storage upload fails**
    - **Impact**: Assessment generated but not saved
    - **Handling**: Retry upload (2-3 attempts), log AI response for manual recovery
    - **Prevention**: Verify storage bucket permissions and quota

11. **Storage bucket quota exceeded**
    - **Impact**: Cannot save new files
    - **Handling**: Return 507 Insufficient Storage with admin alert
    - **Prevention**: Monitor storage usage, implement cleanup policies

12. **Database insert fails (metadata record)**
    - **Impact**: File uploaded but not tracked in database
    - **Handling**: Attempt rollback (delete file), return error
    - **Prevention**: Use database transaction if possible

13. **Duplicate assessment generation**
    - **Impact**: Multiple assessments for same project
    - **Handling**: Check for existing recent assessment, ask to confirm override
    - **Prevention**: Add unique constraint or check before processing

### Network/Infrastructure Issues
14. **Supabase connection timeout**
    - **Impact**: Database or storage operations fail
    - **Handling**: Implement retry logic with timeout increases
    - **Prevention**: Monitor connection health, use connection pooling

15. **n8n workflow timeout**
    - **Impact**: Workflow terminates before completion
    - **Handling**: Increase workflow timeout settings, optimize processing steps
    - **Prevention**: Set realistic timeout (e.g., 5 minutes)

### Security Issues
16. **Unauthorized webhook access**
    - **Impact**: Potential abuse or data exposure
    - **Handling**: Reject requests without valid authentication
    - **Prevention**: Implement webhook secret/token validation

17. **Sensitive data in transcript**
    - **Impact**: PII or confidential info sent to OpenAI
    - **Handling**: Implement PII scrubbing before AI analysis
    - **Prevention**: Add data sanitization step, use Azure OpenAI for data residency

### Error Handling Strategy
- **All critical errors**: Log to n8n error log and optionally send notification (email/Slack)
- **Retry logic**: Implement for transient failures (network, rate limits)
- **Graceful degradation**: Return partial results if possible
- **User feedback**: Always return meaningful error messages in webhook response

## Success Criteria
- ✅ Workflow completes in under 30 seconds (typical case)
- ✅ Assessment document is readable, well-formatted, and actionable
- ✅ File metadata is correctly stored and retrievable from database
- ✅ Error cases return appropriate HTTP status codes and messages
- ✅ Workflow can handle concurrent requests (multiple projects)
- ✅ Generated assessments are consistent in quality and structure

## Future Enhancements (Out of Scope)
- Email notification when assessment is ready
- Integration with CRM to update project status
- Multi-language support for transcripts
- Comparative analysis across multiple demo calls
- Automated scoring and risk classification
- PDF output format option
